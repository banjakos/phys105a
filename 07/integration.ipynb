{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fallen-suffering",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PHYS 105A:  Introduction to Scientific Computing\n",
    "\n",
    "# Numerical Integration of Functions\n",
    "\n",
    "Chi-kwan Chan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-geography",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importance of Integration in Physics\n",
    "\n",
    "* Physical (dynamic) systems are very often described by ordinary differential equations, examples include Newton's second law:\n",
    "   $f = m a = m \\frac{dx^2}{dt^2}$.\n",
    "   \n",
    "* For fields, their are described by partial differential equations.\n",
    "\n",
    "* In order to predict how physical systems behave, we need to integrate these diffrential equations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-python",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nmerical Integration of Functions\n",
    "\n",
    "* But before we learn how to solve generic ODEs, let's learn a simple special case:\n",
    "  $I = \\int_a^b f(x) dx$.\n",
    "\n",
    "* Note that this integration is equivalent to solving for the value $I \\equiv y(b)$ of the differential equation $dy/dx = f(x)$ with the boundary condition $y(a) = 0$.\n",
    "\n",
    "* By doing so, we will learn the important concept of convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-unemployment",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analytical Example\n",
    "\n",
    "* Numerical integration can help us solve problems without analytical solutions.\n",
    "\n",
    "* But to help our understanding, we will first use an example with analytical solution.\n",
    "\n",
    "* Let's consider $f(x) = e^{x}$.\n",
    "\n",
    "* The indefinite integration is $\\int f(x) dx = e^{x} + C$, where $C$ is a constant.\n",
    "\n",
    "* The definite integral is $\\int_a^b f(x) dx = e^{b} - e^{a}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-rogers",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# It is useful to plot the function for visualization.\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "x = np.linspace(0, 1, 101) # define a fine grid for plotting\n",
    "y = f(x)                   # sample function f on the grid\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.fill_between(x, y, alpha=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-softball",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Riemann Sums\n",
    "\n",
    "* When we first learn about ingegration, we usually learn about the Riemann sum first.\n",
    "\n",
    "    $I \\approx S \\equiv \\sum_{i = 1}^n f(x_i^*) \\Delta x_i$\n",
    "  \n",
    "  where $\\Delta x_i = x_i - x_{i-1}$.\n",
    "  \n",
    "* If $x_i^* = x_{i-1}$ for all $i$, then $S$ is called the left Reimann Sum.\n",
    "\n",
    "* If $x_i^* = x_i$ for all $i$, then $S$ is called the right Reimann Sum.\n",
    "\n",
    "* If $x_i^* = (x_{i-1} + x_i)/2$ for all $i$, then $S$ is called the middle Reimann Sum.\n",
    "\n",
    "* There are other Riemann Sums such as the supper and lower Riemann (Darboux) sums.  But we won't discuss them here.  They are useful for prove mathemtical theories but less useful in numerical analysis.\n",
    "\n",
    "* In the limit $\\Delta x_i \\rightarrow 0$, the Riemann Sums converge to the integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-pride",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Graphically, this is the left Reimann Sum\n",
    "\n",
    "X = np.linspace(0, 1, 11) # define a coarse grid for the sum\n",
    "Y = f(X)                  # sample function f on the grid\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.scatter(X[:-1], Y[:-1], color='r')\n",
    "plt.fill_between(X, Y, step='post', color='r', alpha=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-secret",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# And this is the right Reimann Sum\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.scatter(X[1:], Y[1:], color='r')\n",
    "plt.fill_between(X, Y, step='pre', color='r', alpha=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-credits",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# And this is the middle Reimann Sum\n",
    "\n",
    "X = np.linspace(0, 1, 11)\n",
    "X = 0.5 * (X[:-1] + X[1:])\n",
    "Y = f(X)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.scatter(X, Y, color='r')\n",
    "plt.fill_between(np.concatenate([[0], X, [1]]), \n",
    "                 np.concatenate([Y[:1], Y, Y[-1:]]), \n",
    "                 step='mid', color='r', alpha=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-gates",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can easily compute the Riemann sums numerically!\n",
    "#\n",
    "# Here's the left Riemann sum.\n",
    "\n",
    "N = 10\n",
    "D = 1 / N\n",
    "X = [D * i for i in range(N)]\n",
    "S = np.sum(f(X) * D)\n",
    "\n",
    "print('Left Riemann Sum:', S)\n",
    "\n",
    "# And we can compare it with the true answer\n",
    "\n",
    "I = f(1) - f(0)\n",
    "print('Analytical solution:', I)\n",
    "\n",
    "# The difference is\n",
    "print('Error:', abs(I - S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-dining",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Here's the right Riemann sum.\n",
    "\n",
    "N = 10\n",
    "D = 1 / N\n",
    "X = [D * (i+1) for i in range(N)] # note the (i+1) here\n",
    "S = np.sum(f(X) * D)\n",
    "\n",
    "print('Right Riemann Sum:', S)\n",
    "\n",
    "# And we can compare it with the true answer\n",
    "\n",
    "I = f(1) - f(0)\n",
    "print('Analytical solution:', I)\n",
    "\n",
    "# The difference is\n",
    "print('Error:', abs(I - S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-treatment",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Here's the middle Riemann sum.\n",
    "\n",
    "N = 10\n",
    "D = 1 / N\n",
    "X = [D * (i+0.5) for i in range(N)] # note the (i+0.5) here\n",
    "S = np.sum(f(X) * D)\n",
    "\n",
    "print('Right Riemann Sum:', S)\n",
    "\n",
    "# And we can compare it with the true answer\n",
    "\n",
    "I = f(1) - f(0)\n",
    "print('Analytical solution:', I)\n",
    "\n",
    "# The difference is\n",
    "print('Error:', abs(I - S))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-rugby",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* For this particular case, the middle Riemann sum gives us much accurate solution!\n",
    "\n",
    "* This may be clear from the figures already.\n",
    "\n",
    "* However, if we refine the step size, clearly the errors in the left and right Riemann sums will reduce as well.\n",
    "\n",
    "* How does the error depend on the step size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-federal",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's define a function with different parameters\n",
    "# to compute the different types of Riemann Sum.\n",
    "\n",
    "def RiemannSum(f, N=10, a=0, b=1, t='mid'):\n",
    "    D = (b-a) / N\n",
    "    if t[0] == 'l':\n",
    "        X = [D*(i    ) + a for i in range(N)]\n",
    "    elif t[0] == 'r':\n",
    "        X = [D*(i+1  ) + a for i in range(N)]\n",
    "    else:\n",
    "        X = [D*(i+0.5) + a for i in range(N)]\n",
    "    return np.sum(f(np.array(X)) * D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-singer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's now define a different numbers of grid points.\n",
    "\n",
    "Ns = [8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "# And compute the Riemann sums using the different methods\n",
    "err_l = [abs(RiemannSum(f, N, t='l') - I) for N in Ns]\n",
    "err_m = [abs(RiemannSum(f, N, t='m') - I) for N in Ns]\n",
    "err_r = [abs(RiemannSum(f, N, t='r') - I) for N in Ns]\n",
    "\n",
    "# It is cool that the error in the middle Riemann sum, even with\n",
    "# only 8 points, is compariable to the left and right Riemann sums\n",
    "# using ~ 100 points!\n",
    "# It is even more impressive that when we use ~ 1000 points in the\n",
    "# middle Riemann sum, the error is just ~ 1e-7!\n",
    "plt.loglog(Ns, err_l, '+--', color='r', label='left')\n",
    "plt.loglog(Ns, err_m, 'o-',  color='g', label='middle')\n",
    "plt.loglog(Ns, err_r, 'x:',  color='b', label='right')\n",
    "plt.xlabel('Number of sampling points')\n",
    "plt.ylabel('Absolute errors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-showcase",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* It is cool that the error in the middle Riemann sum, even with only 8 points, is compariable to the left and right Riemann sums using ~ 100 points!\n",
    "\n",
    "* It is even more impressive that when we use ~ 1000 points in the middle Riemann sum, the error is just ~ 1e-7!\n",
    "\n",
    "* Is this generically true?\n",
    "\n",
    "* We may create the same convergence plots for different functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-snake",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Test with different functions, this is half cycle of sin()\n",
    "\n",
    "def g(x):\n",
    "    return np.sin(x * np.pi/2)\n",
    "\n",
    "X = np.linspace(0, 1, 11)\n",
    "X = 0.5 * (X[:-1] + X[1:])\n",
    "Y = g(X)\n",
    "\n",
    "plt.plot(x, g(x))\n",
    "plt.scatter(X, Y, color='r')\n",
    "plt.fill_between(np.concatenate([[0], X, [1]]), \n",
    "                 np.concatenate([Y[:1], Y, Y[-1:]]), \n",
    "                 step='mid', color='r', alpha=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-blair",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# And compute the Riemann sums using the different methods\n",
    "err_l = [abs(RiemannSum(g, N, t='l') - 2 / np.pi) for N in Ns]\n",
    "err_m = [abs(RiemannSum(g, N, t='m') - 2 / np.pi) for N in Ns]\n",
    "err_r = [abs(RiemannSum(g, N, t='r') - 2 / np.pi) for N in Ns]\n",
    "\n",
    "# It is cool that the error in the middle Riemann sum, even with\n",
    "# only 8 points, is compariable to the left and right Riemann sums\n",
    "# using ~ 100 points!\n",
    "# It is even more impressive that when we use ~ 1000 points in the\n",
    "# middle Riemann sum, the error is just ~ 1e-7!\n",
    "plt.loglog(Ns, err_l, '+--', color='r', label='left')\n",
    "plt.loglog(Ns, err_m, 'o-',  color='g', label='middle')\n",
    "plt.loglog(Ns, err_r, 'x:',  color='b', label='right')\n",
    "plt.xlabel('Number of sampling points')\n",
    "plt.ylabel('Absolute errors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-recognition",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Test with different functions, this is a quarter circle\n",
    "\n",
    "def h(x):\n",
    "    return np.sqrt(1 - x * x)\n",
    "\n",
    "X = np.linspace(0, 1, 11)\n",
    "X = 0.5 * (X[:-1] + X[1:])\n",
    "Y = h(X)\n",
    "\n",
    "plt.plot(x, h(x))\n",
    "plt.scatter(X, Y, color='r')\n",
    "plt.fill_between(np.concatenate([[0], X, [1]]), \n",
    "                 np.concatenate([Y[:1], Y, Y[-1:]]), \n",
    "                 step='mid', color='r', alpha=0.33)\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-atlas",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# And compute the Riemann sums using the different methods\n",
    "err_l = [abs(RiemannSum(h, N, t='l') - np.pi/4) for N in Ns]\n",
    "err_m = [abs(RiemannSum(h, N, t='m') - np.pi/4) for N in Ns]\n",
    "err_r = [abs(RiemannSum(h, N, t='r') - np.pi/4) for N in Ns]\n",
    "\n",
    "# It is cool that the error in the middle Riemann sum, even with\n",
    "# only 8 points, is compariable to the left and right Riemann sums\n",
    "# using ~ 100 points!\n",
    "# It is even more impressive that when we use ~ 1000 points in the\n",
    "# middle Riemann sum, the error is just ~ 1e-7!\n",
    "plt.loglog(Ns, err_l, '+--', color='r', label='left')\n",
    "plt.loglog(Ns, err_m, 'o-',  color='g', label='middle')\n",
    "plt.loglog(Ns, err_r, 'x:',  color='b', label='right')\n",
    "plt.xlabel('Number of sampling points')\n",
    "plt.ylabel('Absolute errors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-connecticut",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Although the detail errors are different for different curves, the general trends are the same.\n",
    "\n",
    "  * When we increase the number of sampling points by 2, or decrease the size of the step by 2, left and right Riemann sums cuts the error by 1/2.\n",
    "  \n",
    "  * When we increase the number of sampling points by 2, or decrease the size of the step by 2, middle Riemann sums cuts the error by 1/4!\n",
    "  \n",
    "* In general, we say the middle Riemann sum converge faster than the left and right Riemann sums.\n",
    "\n",
    "* However, using the different Riemann sum to discuss numerical integration, while it is formally correct, it is difficult to generalize.  This is espeically true for the middle Riemann sum that requires a different set of sampling points.\n",
    "\n",
    "* Starting in the next slide, we will use the notation used in the numerical recipes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-hudson",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trapezoidal Rule:\n",
    "\n",
    "* We will now stick with the \"vertex\" formulation, i.e. $x_i = a + i \\Delta x$.\n",
    "\n",
    "* Instead of considering the middle Reiman sum, we will use the following apprxoimation.\n",
    "\n",
    "  $\\int_{x_0}^{x_1} f(x) dx =\n",
    "  h \\left[\\frac{1}{2} f_0 + \\frac{1}{2} f_1\\right] + \\mathcal{O}(h^3 f'')$\n",
    "  \n",
    "* This is called the trapezoidal rule.\n",
    "\n",
    "* The error term $\\mathcal{O}(\\ )$ reprsents that the true answer differs from the estimate by an amount that is proportional to $h^3$ and $f''$.\n",
    "\n",
    "* If $f$ is linear, i.e., $f'' = 0$, then the trapezoidal is be extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-express",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Test with different functions, this is a quarter circle\n",
    "\n",
    "X = np.linspace(0, 1, 3)\n",
    "Y = g(X)\n",
    "\n",
    "plt.plot(x, g(x))\n",
    "plt.scatter(X, Y, color='r')\n",
    "plt.fill_between(X, g(X), color='r', alpha=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-printing",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can how program the trapezoidal rule and test it\n",
    "\n",
    "def trapezoidal(f, N=10, a=0, b=1, t='mid'):\n",
    "    X, D = np.linspace(a, b, N+1, retstep=True)\n",
    "    return np.sum((0.5*f(X[1:])+0.5*f(X[:-1])) * D)\n",
    "\n",
    "# And compute the Riemann sums using the different methods\n",
    "err_m = [abs(RiemannSum(g, N, t='m') - 2 / np.pi) for N in Ns]\n",
    "err_t = [abs(trapezoidal(g, N)       - 2 / np.pi) for N in Ns]\n",
    "\n",
    "plt.loglog(Ns, err_m, 'o-',  color='g', label='middle')\n",
    "plt.loglog(Ns, err_t, '+:',  color='r', label='trapezoidal')\n",
    "plt.xlabel('Number of sampling points')\n",
    "plt.ylabel('Absolute errors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-details",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simpson’s Rule\n",
    "\n",
    "* Given that the trapezoidal rule is extact for lienar functions, i.e., first order polynomials, one natural question is if we can construct a rule that is exact for second order polynomials.\n",
    "\n",
    "* It turns out that we can.  The result is called the Simpson's rule:\n",
    "\n",
    "  $\\int_{x_0}^{x_2} f(x) dx =\n",
    "  h \\left[\\frac{1}{3} f_0 + \\frac{4}{3} f_1 + \\frac{1}{3} f_2\\right] + \\mathcal{O}(h^5 f^{(4)})$\n",
    "  \n",
    "* Note that this formulate integrate up to $x_2$.\n",
    "\n",
    "* If we want to integrate to $x_1$ instead, this formulate increase the number of function evaluation.\n",
    "  \n",
    "* The error term $\\mathcal{O}(\\ )$ suggests a much rapider convegent rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-evidence",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can how program the Simpson rule and test it\n",
    "\n",
    "def Simpson(f, N=10, a=0, b=1, t='mid'):\n",
    "    X, D = np.linspace(a, b, N+1, retstep=True)\n",
    "    S = 0\n",
    "    for i in range(N//2):\n",
    "        l = X[2*i]\n",
    "        m = X[2*i+1]\n",
    "        r = X[2*i+2]\n",
    "        S += D * (f(l) + 4*f(m) + f(r)) / 3\n",
    "    return S\n",
    "\n",
    "# And compute the Riemann sums using the different methods\n",
    "err_m = [abs(RiemannSum(g, N, t='m') - 2 / np.pi) for N in Ns]\n",
    "err_t = [abs(trapezoidal(g, N)       - 2 / np.pi) for N in Ns]\n",
    "err_S = [abs(Simpson(g, N)           - 2 / np.pi) for N in Ns]\n",
    "\n",
    "plt.loglog(Ns, err_m, 'o-',  color='g', label='middle')\n",
    "plt.loglog(Ns, err_t, '+:',  color='r', label='trapezoidal')\n",
    "plt.loglog(Ns, err_S, 'x:',  color='b', label='Simpson')\n",
    "\n",
    "plt.xlabel('Number of sampling points')\n",
    "plt.ylabel('Absolute errors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-sierra",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can even generalize it to the Bode's rule\n",
    "\n",
    "def Bode(f, N=8, a=0, b=1, t='mid'):\n",
    "    X, D = np.linspace(a, b, N+1, retstep=True)\n",
    "    S = 0\n",
    "    for i in range(N//4):\n",
    "        x0 = X[4*i]\n",
    "        x1 = X[4*i+1]\n",
    "        x2 = X[4*i+2]\n",
    "        x3 = X[4*i+3]\n",
    "        x4 = X[4*i+4]\n",
    "        S += D * (14*f(x0) + 64*f(x1) + 24*f(x2) + 64*f(x3) + 14*f(x4)) / 45\n",
    "    return S\n",
    "\n",
    "# And compute the Riemann sums using the different methods\n",
    "err_m = [abs(RiemannSum(g, N, t='m') - 2 / np.pi) for N in Ns]\n",
    "err_t = [abs(trapezoidal(g, N)       - 2 / np.pi) for N in Ns]\n",
    "err_S = [abs(Simpson(g, N)           - 2 / np.pi) for N in Ns]\n",
    "err_B = [abs(Bode(g, N)              - 2 / np.pi) for N in Ns]\n",
    "\n",
    "plt.loglog(Ns, err_m, 'o-',  color='g', label='middle')\n",
    "plt.loglog(Ns, err_t, '+:',  color='r', label='trapezoidal')\n",
    "plt.loglog(Ns, err_S, 'x:',  color='b', label='Simpson')\n",
    "plt.loglog(Ns, err_B, 'o:',  color='k', label='Bode')\n",
    "\n",
    "plt.xlabel('Number of sampling points')\n",
    "plt.ylabel('Absolute errors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-notice",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final comments\n",
    "\n",
    "* Based on the previous examples, by increasing the order of the approximations, it is possible to construct numerical integration that converges very rapidly.\n",
    "\n",
    "* For double precision floating point values, the machine accruacy is $\\sim 10^{-16}$.  We saw with Bode's rule, we are already reaching that limit for $\\sim 256$ sampling points.\n",
    "\n",
    "* In practice, for smooth functions, it is even possible to develop numerical integrators that converge exponentially!\n",
    "\n",
    "* However, if the function is not smooth, i.e., with discontinuity, then formally the convergent rate is only first order.  Hence, refining the sampling points near the discontinuity is the only method to provide accurate integration.\n",
    "\n",
    "* Also, the approximations we introduce in this lecture includes the *end points* of the function.  It will be difficult to apply these numerical methods to, e.g., improper integral, or functions with singularity.\n",
    "\n",
    "* For the assignment that we will do in two weeks, we will learn how to modify our integrators to exclude the end points, and use them for improper integral and functions with singularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-ranking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
